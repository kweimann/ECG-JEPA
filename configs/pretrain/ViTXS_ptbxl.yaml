# learnable encoder parameters: 3,600,000
# data
sampling_frequency: 500
channels: [I, II, III, AVR, AVL, AVF, V1, V2, V3, V4, V5, V6]
channel_size: 5000
patch_size: 25
min_block_size: 10
min_keep_ratio: 0.15
max_keep_ratio: 0.25
datasets:
  ptb-xl: 1.
# model architecture
dim: 192
depth: 8
num_heads: 4
pred_dim: 96
pred_depth: 8
pred_num_heads: 4
mlp_ratio: 4.
qkv_bias: False
dropout: 0.
attn_dropout: 0.
num_registers: 1
bias: False
norm_eps: 1.0e-6
layer_scale_eps: 0.
# training
steps: 100_000
batch_size: 2048
encoder_momentum: 0.998
final_encoder_momentum: 0.9995
learning_rate: 1.0e-3
final_learning_rate: 1.0e-6
learning_rate_warmup_steps: 10_000
weight_decay: 1.0e-2
final_weight_decay: 1.0e-1
opt_betas: [0.9, 0.99]
opt_eps: 1.0e-6
gradient_clip: 0
gradient_accumulation_steps: 1
checkpoint_interval: 10_000